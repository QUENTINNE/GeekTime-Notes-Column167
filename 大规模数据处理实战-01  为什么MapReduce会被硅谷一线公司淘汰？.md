# 大规模数据处理实战-01 | 为什么MapReduce会被硅谷一线公司淘汰？

> 这一节的主要内容是作者归纳出的2个MapReduce技术的缺点：高昂的维护成本和达不到用户期待的时间性能。
>
> 个人认为这一节作为开篇，内容覆盖并不够全面，提出的例子也不严谨。评分：★★★☆☆

![img](https://static001.geekbang.org/resource/image/54/ca/54a0178e675d0054cda83b5dc89b1dca.png)

2003 年，MapReduce 的诞生标志着超大规模数据处理第一次革命的开始，而开创这段时代的是论文《MapReduce: Simplified Data Processing on Large Clusters*》。

现在经过十年以上的发展，Google 内部已经几乎没人写新的 MapReduce 。2016 年开始，Google 在对新员工的培训中把 MapReduce 替换成了内部称为 **FlumeJava**（不要和 Apache Flume 混淆）的数据处理技术。

> Hadoop 于 2006 年诞生后没过多久，就成为了互联网行业大数据计算的标准配置，同时也成了 Apache 软件基金会的金牌项目之一。在很长一段时间内，Hadoop 基本上就是大数据的代名词。
>
> 但近年国内外就开始出现唱衰 Hadoop 的声音，Hadoop 不再是权威的大数据技术：像 Spark 和 Kafka 这样的新兴技术正在兴起，以用来支持使用人工智能和机器学习的现代数据应用。
>
> Hadoop 不会消失，也不是所有的数据工作都会迁移到云端，但大数据将越来越被公有云和 Spark 等新技术栈定义。
>
> 参考资料：
>
> 《Hadoop真的要死了吗？》
>
> 《Hadoop不再权威，开源大数据的未来何去何从？》
>
> 《Hadoop 气数已尽！逃离复杂性，拥抱云计算》

## **1、高昂的维护成本**

使用 MapReduce需要严格地遵循分步的 Map 和 Reduce 。当构造更为复杂的处理架构时，往往需要协调多个 Map 和多个 Reduce 任务。

然而每一步的 MapReduce 都有可能出错，于是很多人开始设计自己的协调系统（orchestration）来处理异常。例如做一个状态机（state machine）来协调多个 MapReduce，但这会大大增加整个系统的复杂度。

举例说明。假设需要预测美团的股价，活跃在街头的美团外卖电动车数量可以作为一个重要特征。作为大数据负责人，要处理所有收集到的美团外卖电动车的图片，大致可以分为以下三步：

1. 数据收集；
2. 数据处理；
3. 数据计算。

![img](https://static001.geekbang.org/resource/image/44/c7/449ebd6c5950f5b7691d34d13a781ac7.jpg)

数据的搜集工作需要部分外包或者众包。所以在**数据搜集（Data collection）**部分，通常需要 4 个 MapReduce 任务：

1. 数据导入（data ingestion）：下载分散的照片（比如众包公司上传到网盘的照片）到自己的存储系统。
2. 数据统一化（data normalization）：统一不同的照片格式。
3. 数据压缩（compression）：在质量可接受的范围内，保持最小的存储资源消耗 。
4. 数据备份（backup）：采用一定的数据冗余来降低风险。

仅仅是做完数据搜集这一步，离真正的业务应用还差得远。真实的世界是如此不完美，我们需要一部分**数据质量控制（quality control）**流程，比如：

5. 数据时间有效性验证 （date validation）：检测上传图片的日期是否为所需时间段。

6. 照片对焦检测（focus detection）：筛选掉那些因对焦不准而无法使用的照片。

最后才到你负责的重头戏——找到这些图片里的外卖电动车，这一步因为有了人工的介入最难把控时间。**数据贴标（Labeling）**需要做 4 步：

7. 数据标注问题上传（question uploading）：上传工具并让标注者工作。

8. 标注结果下载（answer downloading）：抓取标注完的数据。
9. 标注异议整合（adjudication）：判定时常会发生的标注异议，比如一个电动车被不同的标注者归属于美团外卖或京东快递电动车。
10. 标注结果结构化（structuralization）: 把可能非结构化的标注结果转化成存储系统接受的结构，让标注结果可用。

因为真实的商业 MapReduce 场景极端复杂，像上面这样 10 个子任务的 MapReduce 系统在硅谷一线公司司空见惯。在应用过程中，每一个 MapReduce 任务都有可能出错，都需要重试和异常处理的机制。所以，协调这些子 MapReduce 的任务往往需要和业务逻辑紧密耦合的状态机。

## **2、无法满足期待的时间性能**

Google 曾经花了 5 年不断优化 MapReduce 流程的效率， 1PB 数据的大规模排序时间从 2007 年的 12 小时，缩短至 2012 年的 0.5 小时，降低为原来的1/24。

Google 开发者在 MapReduce 的性能配置上花了非常多的时间，包括了缓冲大小 (buffer size），分片多少（number of shards），预抓取策略（prefetch），缓存大小（cache size）等等。

例如所谓的分片，是指把大规模的的数据分配给不同的机器 / 工人，流程如下图所示。

![img](https://static001.geekbang.org/resource/image/b0/38/b08b95244530aeb0171e3e35c9bfb638.png)

使用年龄作为分片函数（sharding function），会由于Facebook的用户年龄分布不均衡（在 20~30 岁年龄段的用户最多），导致下图中 worker C 分配到的任务规模远大于其他机器。这时候就会产生掉队者（stragglers）：别的机器已完成 Reduce 阶段，只有 worker C 是仍在工作的掉队机器。

![img](https://static001.geekbang.org/resource/image/5c/91/5c719600021f738e8c7edf82197eac91.png)

当然它也有改进方法。掉队者问题可以通过 MapReduce 的性能剖析（profiling）发现。 如下图所示，箭头处就是掉队的机器。

![img](https://static001.geekbang.org/resource/image/63/ca/6399416524eb0dec1e292ea01b2294ca.png)

因为 MapReduce 的分片配置异常复杂，在 2008 年以后，Google 在 MapReduce 中引进了动态分片技术 (dynamic sharding），大大简化了使用者对于分片的手工调整。

> MapReduce是Google公司的核心计算模型，它将运行于大规模集群上复杂并行计算过程高度抽象为两个函数：Map和Reduce。MapReduce的流行因为它有如下优点：
>
> 1. **易于理解**：简单地实现一些接口，就可以完成一个分布式程序，而且这个分布式程序还可以分布到大量廉价的PC机器运行。也就是说，写一个分布式程序，跟写一个简单的串行程序是一模一样的。MapReduce易于编程的背后是MapReduce通过抽象模型和计算框架把需要做什么（What need to do）与具体怎么做（How to do）分开了，为程序员提供了一个抽象和高层的编程接口和框架，程序员仅需关心其应用层的具体计算问题，仅需要编写少量的应用本身计算问题的程序代码；如何具体完成这个并行计算任务所相关的诸多系统层细节被隐藏起来，交给计算框架去处理——从分布代码的执行到大到数千、小到输几个节点集群的自动调度使用。
> 2. **良好的扩展性**：当计算机资源不能得到满足的时候，可以通过简单的增加机器来扩展它的计算能力。多项研究发现，基于MapReduce的计算性可以随节点数目增长保持近似于线性的增长，这个特点是MapReduce处理海量数据的关键，通过将计算节点增至几百或者几千可以很容易地处理数百TB甚至PB级别的离线数据。
> 3. **高容错性**：MapReduce设计的初衷就是使程序能部署在廉价的PC机器上，这就要求它具有很高的容错性。比如，其中一台机器宕机了，它可以把上面的计算任务转移到另一个节点上运行，不至于这个任务运行失败，而且这个过程不需要人工参与，完全是由Hadoop内部完成的。

## **小结**

这一讲中，我们分析了两个 MapReduce 之所以被硅谷一线公司淘汰的“致命伤”：高昂的维护成本和达不到用户期待的时间性能。

> MapReduce虽然有很多的优势，但是也有它所不擅长的。这里的“不擅长”不代表不能做，而是有些场景下实现的效果差，并不适合用MapReduce来处理。主要表现在以下方面：
>
> 1. **实时计算**：MapReduce无法像Oracle或MySQL那样在毫秒或秒级内返回结果，如果需要大数据量的毫秒级响应，可以考虑使用HBase。
> 2. **流计算**：流计算的输入数据是动态的，这是因为MapReduce自身的设计特点决定了输入数据源必须是静态的，不能动态变化。如果需要处理流式数据可以用Storm、Spark Steaming、Flink等流计算框架。
> 3. **DAG（有向图）计算**：多个应用程序存在依赖关系，后一个应用程序的输入为前一个的输出。在这种情况下，MapReduce并不是不能做，而是使用后每个MapReduce作业的输出结果都会写入磁盘，会造成大量的I/O导致性能非常低下。此时可以考虑用Spark等迭代计算框架。
>
> 参考资料：《[离线和实时大数据开发实战](https://book.douban.com/subject/30234022/)》

文中也提到了下一代数据处理技术雏型。例如 2008 年左右在 Google 西雅图研发中心诞生的 FlumeJava，一举解决了上以上提到的MapReduce 的短板，此外它还带来了一些别的优点：更好的可测试性；更好的可监控性； 1 条数据到 1 亿条数据的无缝扩展，不需要修改一行代码，等等。

在后面的章节中，会深入解析 Apache Beam（FlumeJava 的开源版本），揭开 MapReduce 继任者的神秘面纱。

## **思考题**

如果你在 Facebook 负责处理例子中的用户数据，你会选择什么分片函数，来保证均匀分布的数据分片?

参考答案：

- 把年龄倒过来比如 28 岁 变成 82 来分片
- 使用Consistent hashing是可以很好地解决平均分配和当机器增减后重新hashing的问题。

MR的劣势刚好对应了Spark的优势

1. 通过DAG RDD进行数据链式处理，最终只有一个job，大大降低了大数量MR的维护成本
2. 优先基于内存计算的Spark相对于基于磁盘计算的MR也大幅度提高了计算性能，缩短计算时间

个人觉得，这两点可以作为MR和Spark的主要区别。



> 参考文章：《大数据凉了？No，流式计算浪潮才刚刚开始！》