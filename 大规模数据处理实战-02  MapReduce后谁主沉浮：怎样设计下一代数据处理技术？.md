# 大规模数据处理实战-02 | MapReduce后谁主沉浮：怎样设计下一代数据处理技术？

面对日益复杂的业务逻辑， MapReduce 表现出的不足之处是：1. 维护成本高；2. 时间性能不足。

包括 Google 在内的硅谷一线大厂，内部的技术选择是非常严格的。能成为默认方案的技术，至少需要满足以下条件：

- 经受众多产品线、超大规模数据量（例如亿级用户）的考验；
- 简单易用而被开发者自发采用；
- 通过内部领域内专家的评审；
- 比上一代技术必须要有显著的提高。比如仅仅 10% 的提高远远不够，而需要明显的跃迁提高才能够说服整个公司付出高昂成本进行技术迁移。就看看从 Python 2.7 到 Python 3 的升级花了多少年了，就知道在大厂迁移技术是异常艰难的。

## 我们需要一种技术抽象，让多步骤数据处理变得易于维护

维护协调多个步骤的数据处理在业务中非常常见，我们可以用有向无环图（DAG）来抽象表达。因为有向图能为多个步骤的数据处理依赖关系，建立起很好的模型。

![img](https://static001.geekbang.org/resource/image/26/83/26072f95c409381f3330b77d93150183.png)

有向图中的节点表达成一种通用的数据集，边表达一种通用的数据变换，如此就可以描述极为宏大复杂的数据处理流程。

## 我们不想要复杂的配置，让性能自动进行优化

MapReduce 的另一个问题是配置过于复杂，错误的配置会导致数据处理任务效率低下。这种问题怎么解决呢？很自然的思路就是，让容易犯错的人少做一点，让机器多做一点。我们已经学会用有向图对数据处理进行高度抽象，就可以把它用来自动性能优化。

![img](https://static001.geekbang.org/resource/image/dc/a7/dc07e6cccdcc892bf6dff9a288e7f3a7.jpg)

理想的情况下，计算引擎能自动发现并合并两条重复的数据处理流（例如红线框中的处理番茄）；而针对不再需要的流水线，计算引擎也能在预处理时优化掉无关操作。

除了流水线的优化，另一种是计算资源的自动弹性分配优化。劳动力可以做到按需分配，比如 1000个番茄需要100 台机器处理 ，如果是 10000 个番茄那就分配 1000 台机器。

我想用这样两个例子表达的观点是，在数据处理开始前，我们需要有一个自动优化的步骤和能力，而不是按部就班地就把每一个步骤直接扔给机器去执行。

## 我们要能把数据处理的描述语言，与背后的运行引擎解耦合开来

有向图完全可以作为前后端分离协议，分离数据处理为两部分，描述语言部分和运算引擎部分。而除了有向图表达需要数据处理描述语言和运算引擎协商一致，其他的实现都是灵活可拓展的。

比如，数据描述用 Python 描述由业务团队使用，计算引擎用 C++ 实现由数据底层架构团队维护并且高度优化；或者数据描述在本地写，计算引擎在云端执行。

![img](https://static001.geekbang.org/resource/image/d7/b8/d77857341e194bae59ce099e7d68c9b8.png)

## 我们要统一批处理和流处理的编程模型

批处理处理的是有界离散的数据，比如处理一个文本文件；流处理处理的是无界连续的数据，比如每时每刻的支付宝交易数据。

MapReduce 的一个局限是它仅能实现批处理。后继者 Flink 的批处理可以用Dadaset数据结构实现，流处理用 DataStream。但在现实的业务系统中，批处理和流处理是常常混合共生，或者频繁变换的。

因此我们设计的数据处理框架里，就得有更高层级的数据抽象。首先是批处理和流处理的数据，都用统一的数据结构表示。其次是面对业务需求的改变，开发者能仅使用一套编程API实现修改。

## 我们要在架构层面提供异常处理和数据监控的能力

真正写过大规模数据处理系统的人都深有感触：复杂的数据处理系统中，最难的部分不是系统开发，而是异常处理。

我们可以利用基本的数据监控能力，设计对于数据处理的每一步执行及相关信息提供自动的监控平台，例如监控网站。

## 小结

![img](https://static001.geekbang.org/resource/image/53/2e/53aa1aad08b11e6c2db5cf8bb584572e.png)

后面的章节会补充设计和使用大规模数据处理架构的一些基础知识，同时也会深入剖析Apache Spark 和 Apache Beam，因为这两个大数据处理框架与我们这里的设计理念最接近。

## 思考题

你现在在使用的数据处理技术有什么问题，你有怎样的改进设计？

Unify platform和批流统一已经是主要趋势了，而我个人目前只对spark、flink有一定的了解。对于spark来说，无疑是很优秀的一个引擎，包括它的all in one的组件栈，structured streaming出来后的批流api的统一，目前在做的continues Mode。而flink，的确因为阿里的运营，在国内火了。但也展现了它的独有优势，更加贴近dataflow model的思想。同时，基于社区以及阿里、华为小伙伴的努力，flink的table/sql 的api也得到的很大的增强，提供了流批统一的api。虽然底层然后需要分化为dataset和datastream以及runtime层的batchTask和StreamTask，但是现在也在rethink the stack，这个point在2019 SF 的大会也几乎吸引了所有人。但就现状而言，flink的确有着理念上的优势（流是批的超集），同时也有迅猛上升的趋势。