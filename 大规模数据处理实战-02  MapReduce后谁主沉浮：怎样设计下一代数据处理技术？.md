# 大规模数据处理实战-02 | MapReduce后谁主沉浮：怎样设计下一代数据处理技术？

面对日益复杂的业务逻辑， MapReduce 表现出的不足之处是：1. 维护成本高；2. 时间性能不足。

包括 Google 在内的硅谷一线大厂，内部的技术选择是非常严格的。能被选择作为默认方案的技术，至少需要满足以下条件：

- 经受众多产品线、超大规模数据量（例如亿级用户）的考验；
- 简单易用而被开发者自发采用；
- 通过内部领域内专家的评审；
- 比上一代技术必须要有显著的提高。比如仅仅 10% 的提高远远不够，而需要明显的跃迁提高才能够说服整个公司付出高昂成本进行技术迁移。就看看从 Python 2.7 到 Python 3 的升级花了多少年了，就知道在大厂迁移技术是异常艰难的。

> - 人员角度：团队成员结构、核心开发维护者技术栈
> - 产品角度：产品定位、目标及开发周期
> - 业绩角度：可承担的风险、期望达成的效益
> - 技术角度：社区活跃度、文档完善程度、稳定性、性能、相关工具链
>
> 技术选型方案如何出炉的？ - waterwu的回答 - 知乎 https://www.zhihu.com/question/65350787/answer/331217107

## 我们需要一种技术抽象，让多步骤数据处理变得易于维护

维护协调多个步骤的数据处理在业务中非常常见，我们可以用有向无环图（DAG）来抽象表达。因为有向图能为多个步骤的数据处理依赖关系，建立起很好的模型。

![img](https://static001.geekbang.org/resource/image/26/83/26072f95c409381f3330b77d93150183.png)

有向图中的节点表达成一种通用的**数据集**，边表达一种通用的**数据变换**，如此就可以抽象极为宏大复杂的数据处理流程。

## 我们想要简洁的配置，让性能自动进行优化

MapReduce 的另一个问题是配置过于复杂，错误的配置会导致数据处理任务效率低下。这种问题怎么解决呢？很自然的思路就是，人容易犯错，那就少做一点，让机器多做一点。有向图（DAG）既然可以对数据处理进行高度抽象，也就可以被用来自动性能优化。

![img](https://static001.geekbang.org/resource/image/dc/a7/dc07e6cccdcc892bf6dff9a288e7f3a7.jpg)

理想的情况下，计算引擎能自动发现并合并两条重复的数据处理流（例如红线框中的处理番茄流程）；而针对不再需要的流水线，也能在数据预处理时取消无关步骤。

除了流水线的自动合并及取消优化，另一种是计算资源的自动弹性分配优化。劳动力可以做到按需分配，比如 100台机器处理1000个番茄 ，1000台机器就分配给 10000 个番茄。

在数据处理开始前，需要有一个自动优化的步骤和能力，而不是按部就班地就把每一个步骤直接扔给机器去执行。

## 我们要能把数据处理的描述语言，与背后的运行引擎解耦合开来

有向图可以作为前后端分离（client-server design）协议，分离数据处理为两个步骤，分别描述语言部分和运算引擎部分。而除了有向图表达需要数据处理描述语言和运算引擎协商一致，其他的实现都是灵活可拓展的。

比如，数据描述用 Python 描述由业务团队使用，计算引擎用 C++ 实现由数据底层架构团队维护并且高度优化；或者数据描述在本地写，计算引擎在云端执行。

![img](https://static001.geekbang.org/resource/image/d7/b8/d77857341e194bae59ce099e7d68c9b8.png)

有向图可以作为数据处理的描述语言和运算引擎的前后端分离协议。

## 我们要统一批处理和流处理的编程模型

**批处理**的对象是有界离散的静态历史数据，比如处理一个文本文件；**流处理**的对象是无界连续到达的数据，比如每时每刻的支付宝交易数据。

MapReduce 的一个局限是它仅能实现批处理。后继者 Flink 可以用不同的数据结构分别实现批处理和流处理，批处理用Dataset，流处理用 DataStream。

但在现实的业务系统中，批处理和流处理是常常混合共生，或者频繁变换的。因此我们设计的数据处理框架里，就得有更高层级的数据抽象，满足以下两个需求：

1. 首先是批处理和流处理的数据，都用统一的数据结构表示。
2. 其次是面对业务需求的改变，开发者能仅仅使用一套编程API实现和修改。

## 我们要在架构层面提供异常处理和数据监控的能力

真正写过大规模数据处理系统的人都深有感触：复杂的数据处理系统中，最难的部分不是系统开发，而是异常处理。

Google 的内部调研表明，在大规模的数据处理系统中，90% 的时间都花在了异常处理。

因此需要利用基本的数据监控能力，设计提供数据处理的每一步执行及相关信息的监控平台。

## 小结

![img](https://static001.geekbang.org/resource/image/53/2e/53aa1aad08b11e6c2db5cf8bb584572e.png)

后面的章节会补充设计和使用大规模数据处理架构的一些基础知识，同时也会深入剖析Apache Spark 和 Apache Beam，因为这两个大数据处理框架与我们这里的设计理念最接近。

## 思考题

你现在在使用的数据处理技术有什么问题，你有怎样的改进设计？

Unify platform和批流统一已经是主要趋势了，而我个人目前只对spark、flink有一定的了解。对于spark来说，无疑是很优秀的一个引擎，包括它的all in one的组件栈，structured streaming出来后的批流api的统一，目前在做的continues Mode。而flink，的确因为阿里的运营，在国内火了。但也展现了它的独有优势，更加贴近dataflow model的思想。同时，基于社区以及阿里、华为小伙伴的努力，flink的table/sql 的api也得到的很大的增强，提供了流批统一的api。虽然底层然后需要分化为dataset和datastream以及runtime层的batchTask和StreamTask，但是现在也在rethink the stack，这个point在2019 SF 的大会也几乎吸引了所有人。但就现状而言，flink的确有着理念上的优势（流是批的超集），同时也有迅猛上升的趋势。